\section{Methods}
\label{ref_methods}

In this section, a literature review is conducted to understand and evaluate effective algorithms and techniques for outlier detection.
This review includes scientific literature, library documentation, and online resources.
The goal of this review is to understand the cutting edge techniques and the logic behind algorithm decision-making.
Additionally, a variety of interdisciplinary methods (\textit{e.g.}, Statistics, Deep Learning, etc.) are used to compare ideal use cases for building an anomaly detection pipeline and toolkit.

A review is also presented that determines the most common datasets used to benchmark anomaly detection techniques.
Since anomalies are by nature rare, most datasets contain a very small number of them.
It is critical that the anomalies they do contain are a good representative sample.
Results in Section \ref{ref_dataset_survey} show the most common datasets currently used in literature.

Data collection in this study is performed using the following procedure:
\begin{enumerate}
    \item Pre-process data inline with recommendations from the dataset authors.
    \item Setup the data processing pipelines using the developed anomaly detector.
    \item Execute the pipeline for each experimental dataset.
    \item Tune the detector parameters and optimize for the specific dataset.
    \item Collect and graph the results for anomaly detection analysis.
\end{enumerate}

Data analysis is performed by comparing the results of the detector against the ground truth for the experimental datasets.
Through this analysis the benefits and shortcomings of each method can be understood.
This analysis also helps determine what type of detection methodology works best for the anomalies in this study.
Using this analysis, the best method can be implemented for solving real-world interdisciplinary problems.

\subsection{Measuring Algorithms and Methods}

Algorithms are susceptible to missing detections from challenging phenomena or false positives from non-anomalous points.
A successful detector must weight false detections lower than missed detections.
If a detection is missed, it is much more significant than a false positive, because a false positive can be ignored but a missed detection cannot.
Because of this, many existing algorithms and implementations are being compared to identify the best for the contextual outliers present in the experimental datasets.
This provides insight on the existing shortcomings in the field and shows where the algorithms can be improved.

There are existing industry standards for comparing machine learning techniques.
Some of these include ROC metrics which allow you to compare false positive and true positive rates.
There are also conventional statistical techniques which can be utilized.
The most significant metric for this study is the true positive detection rate.
For a detector to be considered successful, a near 100\% true-positive identification rate is desired.
False positive detection rate is also important, but not as critical, to ensure the detector is not overly noisy.

\subsection{Resources}

We have access to a variety of computational resources from universities and research institutions across Europe.
In Finland, the group has access to the CSC supercomputer.
CSC provided supercomputer resources and hosted cloud services available for the project.
Additionally, the researchers have access to limited computational resources via their personal computers.

\subsection{Dataset Survey}
\label{ref_dataset_survey}

In this section, 17 works focusing on streaming data outlier detection in machine learning are examined.
The datasets used in each paper were examined to determine which datasets were commonly used in the literature as shown in Table \ref{tab:datasets_outlier_detection}.

\newpage
\input{tables/datasets}

Figure \ref{fig_dataset_lit} shows the most commonly occurring datasets in the literature from table \ref{tab:datasets_outlier_detection} are KDD-CUP99 \parencite{kdd1999} followed by Covertype-Forest \parencite{covertype-dataset}.
A dataset is included in Table \ref{tab:datasets_outlier_detection} and Figure \ref{fig_dataset_lit} if there are 2 or more occurrences in the literature surveyed.

\begin{figure}[H]
    %%\centering
    \input{Images/dataset_survey.pgf}
    \caption{Dataset Occurrence in Literature }
    \label{fig_dataset_lit}
\end{figure}

The most commonly used datasets found in the literature were originally created in the late 1990's.
Most of the literature surveyed was conducted in the last 10 years, but the standard benchmark datasets are over two decades old.
This data was collected when the landscape of cyber-attacks and computing looked much different than today. 
These datasets are not sufficient to benchmark performance against modern, sophisticated attacks.
There is a lack of standardization in datasets that makes compareing algorithm performance difficult.

By analyzing the existing datasets, the experimental datasets for this study are selected.
The current industry standard datasets are not sufficient for benchmarking performance in relation to the use cases presented in this study.
In the subsequent section, appropriate and diverse datasets are selected that benchmark the desired outlier phenomenon.

\subsection{Dataset Selection}
\label{ref_datasets}

In this study, three separate datasets are used to test and evaluate the developed detection technique.
The datasets span many disciplines and provide a good survey of the applicability of the proposed detection technique.

\subsubsection{Hydraulic Simulation Dataset}
\label{ref_hydraulic_dataset}

For this experiment, the Matlab software toolkit Simscape Multibody is used to design a model of the hydraulic system outlined in Figure \ref{fig:boom_structure}.
This model is used to study the response of the system to optimize its behavior and parameters.
For this study, a mass ($m$) of 240 kg and a supply pressure of 185 bar is used.

\begin{figure}[H]
    %\centering
    \includegraphics[width=\textwidth]{1_hydraulic_sim/BoomStructure.PNG}
    \caption{Hydraulic Boom Lift Structure}
    \label{fig:boom_structure}
\end{figure}


The square wave profile control signal shown in Figure \ref{fig:hydraulic_cs} is used as input to the simulation of the hydraulic system.
It stays at a neutral voltage of 0 until 0.2 seconds into the simulation.
At 0.2 seconds, the control signal is at its maximum of 10 volts for 0.4 seconds.
Then it falls to become proportionally negative at 0.7 seconds.
After another 0.4 seconds elapsed, the signal returns to the neural position of 0 volts beginning at 1.1 seconds.

\begin{figure}[H]
        %\centering
    \input{1_hydraulic_sim/results/input_sig_u.pgf}
    \caption{Hydraulic System Control Signal}
    \label{fig:hydraulic_cs}
\end{figure}

Figure \ref{fig:hydraulic_pos} shows that introducing a proportionally negative signal does not cause the end effector to return to its initial position.
As the control signal is varied inversely, the position of the end effector only returns halfway to its initial position.
This indicates the system exhibits a non-linear relationship between the control signal and the end effector position.
The system experiences mild oscillation after coming to rest when the control signal returns to zero at the end of the simulation.
To achieve predictable system response and reduce oscillation, a more complex control methodology is required.

\begin{figure}[H]
        %\centering
    \input{1_hydraulic_sim/results/input_sig_pos.pgf}
    \caption{Hydraulic Crane End Effector Position}
    \label{fig:hydraulic_pos}
\end{figure}

\subsubsection{Power Electronic Converter Dataset}
\label{ref_pec_dataset}

Transitioning from conventional power systems to power electronics-dominated grids (PEDG) has increased demand for grid-forming converters (GFM) to facilitate operational reliability.
GFMs have made significant progress in recent years to expedite stability under different grid conditions, but their operation during faults or large signal disturbances still remains a challenge.

Authors \cite{trainsient-stability-9523750} explain that GFMs handle a significantly smaller percentage of over-current (usually only 20\%) compared to synchronous generators (SGs) which can handle seven times their nominal current.
This makes fault detection for GFMs critical to maintain synchronization with the grid.
Since the network infrastructure of power systems keeps expanding, it is important to identify these faults accurately under varying grid parameter uncertainties.

This study examines four faults in the PEC dataset.
The frequency [$f_c$] of the system throughout various fault conditions is used for detection.
Each fault has significantly different characteristics and magnitude.
The faults examined in the study are explained in Table \ref{tab:pec_faults_table}.

\input{tables/pec_faults}

The faults explained in Table \ref{tab:pec_faults_table} are presented visually in Figure \ref{fig:pec-faults-overall-fig}.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.475\textwidth}
        \centering
        \resizebox{\textwidth}{!}{\input{"2_pec_sim/base_sig_f_c_f1.pgf"}}
        \caption{Line-to-Line (LL) Fault}
        \label{fig:ll-fault}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.475\textwidth}
        \centering
        \resizebox{\textwidth}{!}{\input{"2_pec_sim/base_sig_f_c_f2.pgf"}}
        \caption{Three-Phase Sensor Fault}
        \label{fig:three-phase-sensor-fault}
    \end{subfigure}
    \vskip\baselineskip
    \begin{subfigure}[b]{0.475\textwidth}
        \centering
        \resizebox{\textwidth}{!}{\input{"2_pec_sim/base_sig_f_c_f3.pgf"}}
        \caption{Single-Phase Voltage Sag}
        \label{fig:single-phase-voltage-sag}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.475\textwidth}
        \centering
        \resizebox{\textwidth}{!}{\input{"2_pec_sim/base_sig_f_c_f4.pgf"}}
        \caption{Three-Phase Grid Fault}
        \label{fig:three-phase-grid-fault}
    \end{subfigure}
    \caption{PEC Dataset Fault Visualization}
    \label{fig:pec-faults-overall-fig}
\end{figure}


\subsubsection{Cyber Security BETH Dataset}
\label{ref_beth_dataset}

On the Github Discussion Board \parencite{RiverGithub2022} for the popular River \parencite{2020river} Machine Learning library, I proposed using a streaming Local Outlier Factor (LOF) methodology for outlier detection.
Through this discussion, Authors \cite{beth-dataset}, added the BETH dataset to a public repository at Imperial College London which provides easy access for researchers wishing to work on the dataset.
The LOF method is unsuitable for contextual outlier detection and is not selected for implementation in the River library.

The BPF-extended tracking honeypot (BETH) cyber security dataset \parencite{beth-dataset} was released in 2021.
It is still under active development and testing.
A cybersecurity honeypot is a set of computer resources that an organization actively monitors for intrusion detection.
Hackers benefit from exploiting these honeypots but are usually unable to do harm to any production systems.
This makes it an attractive dataset for this study since it reflects the current state of the art in cybersecurity and is one of the first to be designed for uncertainty analysis and anomaly detection.

For this dataset, an ssh vulnerability is exploited where any password entered allows a user to login.
The system is running two auxiliary containers to monitor traffic.
The first is the Berkely Packet Filter (BPF) which examines OS process management calls.
The second monitor logs DNS activity from the system.
This data is collected and parsed over a series of trials to form the dataset.

Authors \cite{beth-dataset} present a number of advantages of this dataset that make it attractive for modern machine learning and anomaly detection research.
This includes:
\begin{inlinelist}
    \item being a large and comprehensive cyber-security dataset
    \item containing modern attack vectors
    \item including benign and attack information for each host that is fully labeled.
\end{inlinelist}

Figure \ref{fig:beth_userid_all} shows the samples from the BETH dataset for the UserID parameter that is used in this study.
This parameter is treated as a continuous data stream that corresponds with the measurement time.
The spikes in the UserID parameter generally correspond with the labeled outliers.

\begin{figure}[H]
        %\centering
    \input{3_beth_sim/base_sig_userId_all.pgf}
    \caption{BETH Dataset Signal}
    \label{fig:beth_userid_all}
\end{figure}

In the BETH dataset, the honypots are deployed in a cloud environment because many major companies utilize cloud computing resources. 
Therefore it is important to understand the attacks that are specifically scanning the cloud provider space compared to the prior datasets which are collected exclusively through on-premise servers.
Typically a dataset is selected to:
\begin{inlinelist}
    \item benchmark and highlight a technique in a specific area or
    \item demonstrate the capabilities and generalizability of a technique to other disciplines.
\end{inlinelist}
The BETH dataset is designed to be useful and easy to work with for machine learning researchers.
It provides large volumes of fully labeled data with an easy to parse format and understandable data points.
In this work, the anomaly detection problem is approached differently than in traditional machine learning approaches which shows the generalizability of the dataset.

\subsection{Algorithm Development}
The code development and experimentation described in this work is available on a public GitHub repository \parencite{BeattieGithub2022}.
The figures and results presented in Section \ref{ref_results} are generated using this code.
This section outlines how the final outlier detector was developed and some of the unsuccessful detection attempts.
Some of the datasets in the repository are private and as such cannot be included in the repository.
The code to perform the analysis is included in the repository and can be adapted to fit similar datasets or problems.

\subsubsection{Unsuccessful Attempts}

Many libraries and algorithms outlined in Section \ref{ref_code_libraries} are tested in this study.
The first attempts utilized techniques from the river ML \parencite{2020river} and pysad \parencite{pysad} libraries.
The tested algorithms in the pysad library include IForestASD, LODA, RSHash, xStream, and Robust Random Cut Forest.
The tested (and only) algorithm from the river library is Half Space Trees.

The algorithms demonstrated good performance for point-wise outliers on a simulated noisy sine wave.
The algorithms performed poorly against the contextual outliers in the Power Electronics Dataset.
The outliers present in the dataets in this study are not pointwise but contextual shaplet outliers.
This shows that the detection techniques for point-wise outliers are not sufficent for detecting contextual outliers.
A review of the outlier taxonomies discussed here is presented in Section \ref{ref_outlier_taxonomy}.

New techniques are selected that meet the following criteria:
\begin{inlinelist}
    \item do not require training of a model or previous knowledge of the data
    \item operate in a streaming context
    \item use a windowed or fix memory and processing allocation.
\end{inlinelist}
This significantly reduces the list of available algorithms and libraries.
Many require model training and do not operate well in non-batch contexts.
The banpei \parencite{banpei} library's Singular Spectrum Transformation (SST) and Hotelling methods also failed to detect the desired anomalies.
The Gradient and Difference detectors in TSOD \parencite{tsod} are also unable to detect the contextual anomalies.

\subsubsection{Matrix Profile Detector}
\label{ref_matrix_profile_detector}

The Matrix Profile algorithm for contextual outlier detection from the STUMPY library \parencite{law2019stumpy} was selected for implementation.
Initial testing with the multivariate matrix profile demonstrated good performance but was very computationally expensive and slow.
Additionally, the library did not facilitate an iterative computation for this method so each iteration would need to recompute the entire matrix profile across the whole window.

Because of this, the univariate matrix profile is used in this study.
It is faster and allows for iterative updates to the matrix which is significantly more efficient.
An outlier model class is created to compute the matrix profile for each iteration and predict whether the current event is an outlier.

This technique is used in Section \ref{ref_results} to detect outliers in a variety of situations.
It requires adjusting three parameters based on the characteristics of the data being analyzed.
This is less than the number of parameters required by most machine learning techniques.
Additionally, it relies strictly on statics computations and is therefore explainable without reverse engineering.

\begin{equation}
    \label{eqn:mp_decission}
    \epsilon_{[i]} = \max_{mp} \geq \left(\mu_{mp} + \left(\sigma_{mp} \cdot \alpha\right)\right)
\end{equation}

Let $\alpha$ be the standard deviation ($\sigma$) multiplication factor in Equation \eqref{eqn:mp_decission}.
This equation is used to calculate anomalies by determining the current mean value and comparing it against a multiplier of the standard deviation of the matrix profile.
This equation is parameterized in code so the user can set the data window size, analysis window size, standard deviation multiplier, and other parameters to tune detection.
Optional filters are included to avoid triggering while the detector is still loading data into the analysis window and on recent faults to avoid redundant detection.

\subsubsection{Detection Filters}

\begin{equation}
    \label{eqn:mp_geq_zero}
    \lambda_{[i]} = \left| \epsilon_{[i]} - \max_{mp} \right| > 0.01
\end{equation}

Equation \eqref{eqn:mp_geq_zero} shows a filter for the detector to ensure that the currently calculated metric ($\epsilon$) is representative enough to trigger a detection.
If this condition is not true, there is not enough information to conclude definitively that the point is an outlier.
Therefore, it should not trigger detection.

In certain datasets, like the BETH dataset, performance was inadequate without filtering.
A significant number of false positives were detected before the implementation of the rolling range filter.

\begin{equation}
    \label{eqn:mp_rolling_range}
    \gamma_{[i]} = \max_{mp} - \min_{mp} > \left(\mu_{\epsilon[(n-5)...n]} \cdot \beta \right)
\end{equation}

In Equation \eqref{eqn:mp_rolling_range}, the rolling range average ($\mu$) is multiplied by a scaling factor ($\beta$).
The range in the window is computed during every iteration by subtracting the maximum and minimum value.
A ring buffer is implemented to store the rolling range values.
In this buffer, only 5 elements are allowed and when a new element is inserted the last element is removed.
This means that only the 5 most recent elements are available at a time.

To be stored in the buffer, the current range must be greater than the average of the rolling range ring buffer multiplied by the standard deviation multiplier.
If this is the case, the current range is appended to the rolling range ring buffer and is considered an anomaly.

\subsubsection{Triggering Detection}

Using the matrix profile and the filters developed above, each data point is evaluated and determined to be anomalous or normal.

\begin{equation}
    \label{eqn:mp_cumulative}
    \text{anomaly}_{[i]}=
    \begin{cases}
        true,& \text{if } \epsilon_{[i]} \land \lambda_{[i]} \land \gamma_{[i]}\\
        false,              & \text{otherwise}
    \end{cases}
\end{equation}

The anomaly level is calculated using Equations \eqref{eqn:mp_decission}, \eqref{eqn:mp_geq_zero}, and \eqref{eqn:mp_rolling_range} respectively.
To be determined anomalous, the point ($i$) must satisfy all the conditions in Equation \eqref{eqn:mp_cumulative}.
If a point does not satisfy these conditions, it is not considered anomalous and it subsequently does not trigger the detector.
The combination of the matrix profile algorithm and targeted filters enable the developed detector to be flexible and robust to a wide range of datasets and window sizes.
