\section{Methods}
\label{ref_methods}

To understand and evaluate effective algorithms and techniques for outlier detection, a literature review will be conducted. This review will include both scientific literature, library api documentation, and online resources. The goal of this review will be to understand the cutting edge techniques and the logic behind the decision making of the algorithms. Additionally, the researchers will examine a variety of interdisciplinary methods (ex. statistics, Deep Learning, etc.) to compare ideal use cases in given scenarios to build an anomaly detection pipeline and toolkit.  

The researchers will also survey the existing literature to determine the most popular and common datasets used to benchmark these anomaly detection techniques. Since anomalies are by nature rare, most datasets contain a very small number of them, and it is critical that the anomalies they do contain are a good representative sample. The researchers have conducted preliminary investigations in section \ref{ref_results} that show the most common datasets currently used in literature.  Additionally, through a discussion on improving existing machine learnign techniques in python, the researchers have contacted experts in the field, a Ph.D candidate in machine learning at Imperial College London and an industry cyber-security expert to evaluate the shortcomings in the "standard" datasets for modern applications. 

Data collection will be performed as follows:
\begin{enumerate}
    \item Setup data processing pipelines for a variety of existing anomaly detection techniques.
    \item Create a simulation data set with pre-marked, simple anomalies (ex. sensor failure) 
    \item Graph the data to understand the different type of faults/anomalies to be detected
    \item Setup an algorithm pipeline to run the data through multiple streaming and non-streaming techniques and collect results
    \item Select a real dataset and identify or use pre-identified markers for anomalies
    \item Run the datasets through the algorithm pipeline and collect results
    \item Add additional components (drift detection, etc) to the pipeline and record data results 
\end{enumerate}

Data  analysis will be performed as follows:
\begin{enumerate}
    \item Compare results between different algorithms and techniques (ex. streaming vs. batch, statistical vs. streaming ML) methods for the dataset 
    \item Determine the benefits and shortcomings of each method using standard performance metrics and identify for what type of anomalies certain methods excel
    \item Implement the best methods for the given problem in a real-world control systems problem
\end{enumerate}

\subsection{Measuring Algorithms and Methods}

There will always be phenomena the algorithm cannot detect or behavior that is not anomalous that the algorithm detects accidentally. The goal is to optimize these behaviors for the given task. Therefore, many existing algorithms and implementations are being compared. This comparison will identify which algorithms perform the best for the task and will help identify which techniques are best for which types of data. This will provide insight on the existing shortcomings in the field and will show where the algorithms can be improved.

There are industry standard ways of comparing machine learning techniques. Some of these include ROC curves which allow you to compare false positive and true positive rates. There are also conventional statistical techniques which can be utilized. The researchers will explore further to determine which metrics are most appropriate for the task.

\subsection{Reliability, validity, and sensitivity aspects}
Anomalies will be identified (or pre-identified) in the dataset. Then the experimental results will be examined to see if the algorithm detected the anomalies correctly. When analyzing this data, the researchers will try to determine why certain false or true positives and negatives are occurring and propose techniques to mitigate them.

In the preliminary research considerations the researchers are analyzing and determining appropriate datasets for the experiments. One of the considerations is are the current industry standard datasets sufficient for benchmarking performance for modern algorithms. The researchers suspect that they are not, and thus will utilize a systematic technique to select appropriate and diverse datasets to adequately obtain valid algorithmic results that can be generalized to real world phenomena. 


\subsection{Resources}

The researchers have access to a variety of computational resources from universities and research institutions across Europe. In Finland the group has access to the CSC supercomputer. CSC provided some supercomputer resources and hosted cloud services available for the project. Additionally, the researchers have access to limited computational resources via their personal computers. Additionally, Each university in the consortium has access to additional compute resources that can be utilized by their respective members.

\subsection{Dataset Selection}
\label{ref_datasets}

In this research, three separate data sets will be used to test and evaluate the developed detection technique. The data sets span many fields of engineering and technology and provide a good survey of the generalizeability and applicability of the proposed detection technique.  

\subsubsection{Hydraulic Simulation Dataset}
\label{ref_hydraulic_dataset}

In this study, the Matlab software toolkit Simscape Multibody will be used to design a model of the hydraulic system outlined in figure \ref{fig:boom_structure}. This model will be used to study the behavior and response of the system to optimize behavior and system parameters. For this study, a mass m of 240 KG and a supply pressure of 185 bar is used.

\begin{figure}[H]
    %\centering
    \includegraphics[width=0.8\textwidth]{1_hydraulic_sim/BoomStructure.PNG}
    \caption{Hydraulic Boom Lift Structure}
    \label{fig:boom_structure}
\end{figure}


The control signal shown in figure \ref{fig:hydraulic_cs} is used as input to the simulation of the hydraulic cylinder. This control signal is proportionally negative to the original control signal.

\begin{figure}[H]
    %\centering
    \input{1_hydraulic_sim/results/input_sig_u.pgf}
    \caption{Hydraulic System Control Signal}
    \label{fig:hydraulic_cs}
\end{figure}

Figure \ref{fig:hydraulic_pos} shows the pressure for the system over time. Introducing a proportionally negative signal does not cause the end effector to return to its initial position. As the control signal is varied inversely, the position of the end effector only returns halfway to its initial position. This indicates the system exhibits a non-linear relationship between the control signal and the end effector position.    The system experiences mild oscillation after coming to rest when the control signal is back to zero at the end of the simulation. To achieve predictable system response and reduce oscillation, a more complex control methodology would be required.

\begin{figure}[H]
    %\centering
    \input{1_hydraulic_sim/results/input_sig_pos.pgf}
    \caption{Hydraulic Crane End Effector Position}
    \label{fig:hydraulic_pos}
\end{figure}

\subsubsection{Power Electronic Converter Dataset}
\label{ref_pec_dataset}

Transitioning from the conventional power systems to power electronics-dominated grids (PEDG) has increased demand for grid-forming converters (GFM) to facilitate operational reliability. Although significant research has been made on GFMs (as shown in Figure \ref{fig:sys}) to expedite stability under different grid conditions, its operation during faults or large signal disturbances still remain a challenge. \enquote{Compared to synchronous generators (SGs) that can support up to seven times over their rated current, power converters can only cope with a small percent of overcurrent (typically 20\%). Therefore, GFMs have to be protected against extreme faults (ex. short circuit, line-tripping/reclosing, etc) while being able to stay synchronized to the power system.}\parencite{trainsient-stability-9523750} Since the network infrastructure of power systems keeps expanding, it is important to identify these faults accurately under varying grid parameter uncertainties.

\begin{figure}[H]
	\includegraphics[width=0.65\textwidth]{Images/GFMSchema.pdf}
	\caption{Main circuit and control system structure of a grid-forming converter.}
	\label{fig:sys}
\end{figure}


In this dataset there are four faults considered below. This study will examine the frequency ($f_c$) of the system throughout various fault conditions. Figure \ref{fig:pec_all} shows the entire $f_c$ signal. Each fault has significantly different characteristics and magnitude. The faults are magnified and explained individually below.

\begin{figure}[H]
    %\centering
    \input{2_pec_sim/base_sig_f_c_all.pgf}
    \caption{PEC Data Set $f_c$ Signal}
    \label{fig:pec_all}
\end{figure}

Figure \ref{fig:pec_ll_fault} illustrates the frequency behavior during a line-to-line (LL) Fault. A LL Fault is also referred to as an unsymmetrical fault and occurs when there is a short circuit between two conductors. In three phase power, this can occur between two phases of the system. This fault causes a significant decrease in frequency that is orders of magnitude greater than the standard frequency of the system. 

\begin{figure}[H]
    %\centering
    \input{2_pec_sim/base_sig_f_c_f1.pgf}
    \caption{PEC Data Set LL Fault}
    \label{fig:pec_ll_fault}
\end{figure}

Figure \ref{fig:pec_three_phase_sensor} shows the frequency behavior during a three phase sensor fault. In this fault condition, there is nothing wrong with the system itself but the sensor is faulty. This causes the detected frequency to rise slightly. This slight rise is significantly less than the other examined faults and is very close to the reference frequency of 50 Hz. 

\begin{figure}[H]
    %\centering
    \input{2_pec_sim/base_sig_f_c_f2.pgf}
    \caption{PEC Data Set Three Phase Sensor Fault}
    \label{fig:pec_three_phase_sensor}
\end{figure}

Figure \ref{fig:pec_three_phase_grid_fault} shows the frequency behavior of the system during a single phase voltage sag. When this occurs, the frequency oscillates continuously until the fault is over. This is a significant fault in the system and detection is critical to take remedial action. This is another fault where the magnitude is not very large in comparison to the LL Fault of the Three Phase Grid Fault.

\begin{figure}[H]
    %\centering
    \input{2_pec_sim/base_sig_f_c_f3.pgf}
    \caption{PEC Data Set Single Phase Sag}
    \label{fig:pec_single_phase_sag}
\end{figure}

Figure \ref{fig:pec_three_phase_grid_fault} shows the frequency behavior of the system during a Three Phase Grid Fault. This is another sever fault where there is a problem with the grid and corrective action needs to be taken promptly. In this fault there is a large magnitude drop in frequency for the duration of the fault. This is similar behavior to the Three Phase Sensor Fault but the frequency change of the difference is orders of magnitude larger and in the negative direction.

\begin{figure}[H]
    %\centering
    \input{2_pec_sim/base_sig_f_c_f4.pgf}
    \caption{PEC Data Set Three Phase Grid Fault}
    \label{fig:pec_three_phase_grid_fault}
\end{figure}


\subsubsection{Cyber Security BETH Dataset}
\label{ref_beth_dataset}

The BPF-extended tracking honeypot (BETH) cyber security dataset was released in 2021 and is still under active development and testing. This makes it an attractive dataset for this study since it reflects the current state of the art in cybersecurity and is ``the first cyberscurity dataset for uncertainty and robustness benchmarking \parencite{beth-dataset}.'' A cybersecurity honeypot is a set of computer resources that present a benefit to a hacker if they are exploited but are actively being monitored by an organization or individual. For this dataset, an ssh vulnerability is exploited where any password entered will allow a user to login. The system is running two auxillary containers to monitor traffic. The first is the Berkely Packet Filter (BPF) which examines OS process management calls. The second monitor logs DNS activity from the system. This data is collected and parsed over a series of trials to form the dataset.

The authors present a number of advantages of this dataset that make it attractive for modern machine learning and anomaly detection research \parencite{beth-dataset}:

\begin{enumerate}
    \item At over eight million data points, this is one of the largest cyber security datasets available
    \item It contains modern host activity and attacks
    \item It is fully labelled
    \item It contains highly structured but heterogeneous features 
    \item Each host contains benign activity and at most a single attack, which is ideal for behavioural analysis and other research tasks.
    \item Further data is currently being collected and analysed to add alternative attack vectors to the dataset
\end{enumerate}

Figure \ref{fig:beth_userid_all} shows the samples from the BETH dataset where there are labeled outliers. This study is examining the UserId parameter and using it as a continuous data stream. The spikes in the UserId parameter generally correspond with the labeled outliers.

\begin{figure}[H]
    %\centering
    \input{3_beth_sim/base_sig_userId_all.pgf}
    \caption{BETH Data Set Signal}
    \label{fig:beth_userid_all}
\end{figure}


\subsection{Algorithm Development}

The code development and experimentation for this work is contained in a public Github Repository \parencite{BeattieGithub2022}. Most of the figures and results presented in section \ref{ref_results} will be generated from this code. This section outlines how the final outlier detector was developed and some of the unsuccessful detection attempts along the way. Some of the datasets in the repository are private and as such cannot be included in the repository. The code to perform the analysis is included in the repository and can be adapted to fit similar datasets or problems.

\subsubsection{Unsuccessful Algorithms}

The author experimented with many of the libraries and algorithms outlined in section \ref{ref_code_libraries}. The first iteration of development involved using techniques from the river ML \parencite{2020river} and pysad \parencite{pysad} libraries.  The tested algorithms in the pysad library include IForestASD, LODA, RSHash, xStream, and Robust Random Cut Forest. The tested (and only) algorithm from the river library is Half Space Trees. Initial experimentation was performed and the algorithms demonstrated good performance for point wise outliers on a simulated noisy sine wave. Following this, the algorithms were tested against the Power Electronics Dataset and all techniques performed poorly. These techniques are all well suited to point wise outliers. At this point, the author realized that the kind of anomalies present in the Power Electronics Dataset (and other datasets in this study) are not pointwise but are instead contextual shaplet outliers. A new detection methodology would be needed as the tested algorithms were unable to detect the contextual outliers.

The author then reexamined the available libraries and searched for ones that do not require training of a model or previous knowledge of the data, operate in a streaming context, and can use a windowed or fix memory and processing allocation. This significantly reduces the list of available algorithms and libraries as many required model training and do not operate well outside a batch context. The author evaluated the banpei \parencite{banpei} library's Singular Spectrum Transformation (SST) and Hotelling methods and the library was unable to detect the desired anomalies. The author also evaluated the Gradient and Difference detectors in TSOD \parencite{tsod} and those algorithms were also unable to detect the contextual anomalies.

\subsubsection{Matrix Profile}

Finally, the author found a suitable algorithm for contextual outlier detection called Matrix Profile from the stumpy library \parencite{law2019stumpy}. Initial testing with the multivariate matrix profile demonstrated good performance but was very computationally expensive and slow. Additionally, the library didn't facilitate an iterative computation for this method so each iteration would need to recompute the entire matrix profile across the whole window. Subsequently, the author selected to use the univariate matrix profile, which was faster, and allowed for iterative updates to the matrix profile which can be preformed efficiently. Following successful initial experimentation, the author designed an outlier model class which would compute the matrix profile using the stumpy library on every iteration, and predict whether the current event was an outlier or not. 

Initially the prediction metric was based on determining if the current mean value is greater then a multiplier of the standard deviation of the matrix profile. This worked well but often triggered false positives. This class was parameterized so the user can set the data window size, analysis window size, standard deviation multiplier, and other parameters. Filters were added to not trigger when the algorithm was still loading data into the analysis window and had recently triggered a fault to avoid redundant detection. An additional filter was added to ensure that the currently calculated metric minus the current max value is greater than zero. If it is not there is not enough information to conclude definitely the point is an outlier and it should not be flagged. This technique is used in section \ref{ref_results} to detect outliers in a variety of situations. It only requires adjusting three parameters based on the characteristics of the data being analyzed, much less than is traditionally required by machine learning techniques. Additionally it relies completely on mathematical calculations and statics and is therefore explainable in a way many machine learning techniques are not. 

\subsubsection{Rolling Range Detector}

The detector was fairly well tuned but in certain datasets, like the BETH dataset, performance was inadequate. There were many false positives being reported from the detector. After analysis of the values computed during each iteration,
a rolling range calculation and filter was implemented. With this technique, every iteration the range in the window is computed by subtracting the maximum and minimum value. A ring buffer is implemented to store the rolling range values. In this buffer, only a set number of elements are allowed in the buffer and when a new element is inserted the oldest element is purged from the buffer. If the current range is greater than the average of the rolling range ring buffer multiplied by the standard deviation multiplier, then it is considered an anomaly. If this is the case the current range is appended to the rolling range ring buffer. This improved performance significantly for datasets like the hydraulic simulation and BETH dataset.