\section{Results}
\label{ref_results}

The results from the the two literature reviews are presented here. Additionally, the results of the experiments with the STUMPY python library implementation of the Iterative Matrix Profile detector are presented.

\subsection{Data Set Survey}
In this section, the researchers surveyed 8 works focusing on streaming data outlier detection in machine learning. The datasets used in each paper were examined to determine which datasets were commonly used in the literature as shown in Table \ref{tab:datasets_outlier_detection}. 

\input{tables/datasets}

Figure \ref{fig_dataset_lit} shows the most commonly occurring data sets in the literature from table \ref{tab:datasets_outlier_detection} are KDD\_CUP99 \parencite{kdd1999} followed by Covertype-Forest \parencite{covertype-dataset}. A data set is included in table \ref{tab:datasets_outlier_detection} and figure \ref{fig_dataset_lit} if there are 2 or more occurrences of it in the literature surveyed. The most commonly used datasets found in the literature were originally created in the late 1990's. Most of the research surveyed has been conducted in the last 10 years but the standard benchmark datasets are from the late 90's. This suggests a lack of standardization in data sets to compare algorithm performance. Most papers surveyed included these seemingly standard datasets while also utilizing a wide variety of custom, private, or less well known datasets. Further research should be conducted to determine if the existing standard datasets are sufficient to benchmark performance for modern streaming outlier detection algorithms. If they are not, a standard test suite or data set should be proposed to uniformly evaluate performance across different works.

\begin{figure}[h]
    %%\centering
    \begin{tikzpicture}
        \pie[sum=auto]{6/KDD\_CUP99, 4/Covertype-Forest, 3/Shuttle, 2/UCI\_Pendigit, 2/UCI\_Vowel}
    \end{tikzpicture}
    \caption{Data Set Occurrence in Literature }
    \label{fig_dataset_lit}
\end{figure}

\subsubsection{Discussion with Experts}

The author began a discussion on the Github Discussion Board \parencite{RiverGithub2022} for the popular River \parencite{2020river} Machine Learning library. The post discusses plans to include a streaming Local Outlier Factor (LOF) methodology to the library and test its effectiveness. Through this discussion the author realized that this approach is not the best solution for this given task. Through this discussion, the author was introduced to the BETH dataset \parencite{beth-dataset}, which will be used as one of the experimental test datasets for the developed technique. Additionally, this discussion prompted the author of the BETH dataset, Kate Highnam, to add the dataset to a public repository at Imperial College London which provides easy access for researchers wishing to work on the dataset.

The author also connected with private cyber security researcher Matti Bispham \parencite{Bispham-email:private} at the National Composites Centre National Composites Centre (NCC) Group. Through this correspondence, Matti provided some practical issues with the most popular cited dataset, KDD\_CUP99, mostly corresponding to the age of the dataset including:

\begin{itemize}[leftmargin=2cm]
    \item Cyber-attacks have changed dramatically since 1999 (when KDD\_CUP99 was published). They have a different ontology and language (ex. Crypto mining, Ransomware, etc.)
    \item New network protocols have been developed and eclipsed or significantly modified older standards (ex. HTTP)
    \item System data logging has changed significantly
\end{itemize}

Matti also identified some potential shortcomings of the BETH dataset principally related to the data available including:

\begin{itemize}[leftmargin=2cm]
    \item The data was collected across many days, but only for a short period of consecutive time, around 5 hours.
    \item The exploited vulnerability was an SSH one where the attacker was granted access as long as they entered any password. This immediately classifies the types of attackers who will try to access the system as unsophisticated actors.
    \item Only DNS network logs (not SSH logs) are available.
\end{itemize}

The author additionally connected with Kate Highnam \parencite{Highnam-email:private}, the creator of the BETH dataset to understand additional aspects of the datasets discussed previously. Her original paper states ``The KDD1999, NSLKDD, and ISCX datasets contain network traffic, while the DARPA1998 dataset also includes limited process calls. However, these datasets are at best almost a decade old, and are collected on in-premise servers \parencite{beth-dataset}.'' In the BETH dataset, the honypots are deployed in a cloud environment because many major companies utilise compute through cloud providers. Therefore it is important to understand the attacks that are specifically scanning the cloud provider space compared to the prior datasets which are collected exclusively through on-prem servers. Additionally she expands that ``Typically one chooses a dataset for either of those reasons: to demonstrate the impact of a model in a specific area or the capabilities of the model (and thus extendable to other areas)  or the capabilities of the model (and thus extendable to other areas).'' The BETH dataset is designed in a way that machine learning researchers looking for applications can find it useful. In this work it is used in this way, by approaching the anomaly classification problem from a different angle than traditional machine learning techniques.

\subsection{Anomaly Detection Results}

In this section, the datasets from section \ref{ref_datasets} are tested using the developed matrix profile anomaly detection technique. The parameters for each trail are listed and the results are explain. Further analysis is performed in section \ref{sec:discussion}.

\subsubsection{Hydraulic Simulation Data Set}
\label{ref_results_hydraulic_sim}
The hydraulic simulation data set presented in section \ref{ref_hydraulic_dataset} is used to perform this simulation. Table \ref{tab:hydraulic_sim_params} specifies the parameters used with the anomaly detector to obtain the results in this section. This is the smallest dataset tested in this study and it outlines the performance and characteristics of the anomaly detector at small window sizes. The standard deviation multiplier is the default for the detector. If the data follows a standard Gaussian distribution, the detected points would fall outside 99.7\% of the data present in the window, which would represent a significant outlier comparative to the rest of the data. The same principal applies to the rolling range multiplier. The recent range detection debounce multiplier is also standard given the small window size and ensures that there are not over-noisy or duplicate detections.

\begin{table}[H]
%%\centering
\begin{tabular}{|l|c|l|}
    \hline
	\textbf{Parameter} & \textbf{Value} & \textbf{Description} \\ \hline
	m & 15 & Window Size \\ \hline
	ts$\_$size & 30 & Time Series Size \\ \hline
	std$\_$dev & 3 & Standard Deviation Multiplier \\ \hline
	range & 3 & Rolling Range Multiplier\\ \hline
	recent & 2 & Recent Detection Debounce\\ \hline
\end{tabular}
\caption{Hydraulic Simulation Detector Parameters}
\label{tab:hydraulic_sim_params}
\end{table}

Figures \ref{fig:hydraulic_sim_standard_force} and \ref{fig:hydraulic_sim_signal_force} show the original control signal with the anomaly detections from the experiment highlighted with red lines. In this case, the detector was able to locate all of the inflection points where the signal changed for both control signals without false positives. This is a 100\% accuracy rate for the two different control signals presented with the same detector parameters.

% \begin{figure}[H]
%     \begin{minipage}[t]{0.5\linewidth}
%         %%\centering
%         \resizebox{\linewidth}{!}{\input{1_hydraulic_sim/results/outlier_result_Sim_Standard_force:1.pgf}}
%         \caption{Force Anomalies}
%         \label{fig:hydraulic_sim_standard_force}
%     \end{minipage}
%     \begin{minipage}[t]{0.5\linewidth}
%         %%\centering
%         \resizebox{\linewidth}{!}{\input{1_hydraulic_sim/results/outlier_result_Sim_Signal_force:1.pgf}}
%         \caption{Force Anomalies New CS}
%         \label{fig:hydraulic_sim_signal_force}
%     \end{minipage}
% \end{figure}

Figures \ref{fig:mp_hist_standard_force} and \ref{fig:mp_hist_signal_force} shows the values calculated during the matrix profile for the force generated by the system with the original control signal (figure \ref{fig:hydraulic_sim_standard_force}) and modified control signal (figure \ref{fig:hydraulic_sim_signal_force}) respectively. The values remain relatively similar until the differences in the two signals occur near time step 150. This reveals how the detector is operating and provides an explanation for the system output. 

% \begin{figure}[H]
%     \begin{minipage}[t]{0.5\linewidth}
%         %%\centering
%         \resizebox{\linewidth}{!}{\input{1_hydraulic_sim/results/mp_hist_Sim_Standard_force:1.pgf}}
%         \caption{Force Matrix Profile}
%         \label{fig:mp_hist_standard_force}
%     \end{minipage}
%     \begin{minipage}[t]{0.5\linewidth}
%         %%\centering
%         \resizebox{\linewidth}{!}{\input{1_hydraulic_sim/results/mp_hist_Sim_Signal_force:1.pgf}}
%         \caption{Force Matrix Profile New CS}
%         \label{fig:mp_hist_signal_force}
%     \end{minipage}
% \end{figure}

Figures \ref{fig:hydraulic_sim_standard_pressure} and \ref{fig:hydraulic_sim_signal_pressure} show the original control signal with the anomaly detections from the experiment highlighted with red lines. In this case, the detector was able to locate all of the inflection points in the same locations as previously detected. This provides a 100\% accuracy rate for the two different control signals as is above. The amplitude and waveform of the signals presented here are identical to the force signal presented above. The primary difference is the different amplitudes. The pressure signal is two orders of magnitude larger in amplitude. Which illustrates the detector is robust to scale variations. 

% \begin{figure}[H]
%     \begin{minipage}[t]{0.5\linewidth}
%         %%\centering
%         \resizebox{\linewidth}{!}{\input{1_hydraulic_sim/results/outlier_result_Sim_Standard_pA:1.pgf}}
%         \caption{Pressure Anomalies}
%         \label{fig:hydraulic_sim_standard_pressure}
%     \end{minipage}
%     \begin{minipage}[t]{0.5\linewidth}
%         %%\centering
%         \resizebox{\linewidth}{!}{\input{1_hydraulic_sim/results/outlier_result_Sim_Signal_pA:1.pgf}}
%         \caption{Pressure Anomalies New CS}
%         \label{fig:hydraulic_sim_signal_pressure}
%     \end{minipage}
% \end{figure}

Figures \ref{fig:mp_hist_standard_pressure} and \ref{fig:mp_hist_signal_pressure} shows the values calculated during the matrix profile for the pressure generated by the system with the original control signal (figure \ref{fig:hydraulic_sim_standard_pressure}) and modified control signal (figure \ref{fig:hydraulic_sim_signal_pressure}) respectively. As in the previous signal, the values remain relatively similar until the differences in the two signals occur near time step 150. The waveform of the matrix profile values is identical to the previous force plots with the difference in the magnitude as is noted above. This provides insight into the robustness of the algorithm against different macro data scales of signals with the same shape.

% \begin{figure}[H]
%     \begin{minipage}[t]{0.5\linewidth}
%         %%\centering
%         \resizebox{\linewidth}{!}{\input{1_hydraulic_sim/results/mp_hist_Sim_Standard_pA:1.pgf}}
%         \caption{Pressure Matrix Profile}
%         \label{fig:mp_hist_standard_pressure}
%     \end{minipage}
%     \begin{minipage}[t]{0.5\linewidth}
%         %%\centering
%         \resizebox{\linewidth}{!}{\input{1_hydraulic_sim/results/mp_hist_Sim_Signal_pA:1.pgf}}
%         \caption{Pressure Matrix Profile New CS}
%         \label{fig:mp_hist_signal_pressure}
%     \end{minipage}
% \end{figure}

\subsubsection{Power Electronic Converter Data Set}
\label{ref_results_pec_sim}
The Power Electronic Converter (PEC) data set presented in section \ref{ref_pec_dataset} is used to perform this simulation. Table \ref{tab:pec_sim_params} specifies the parameters used with the anomaly detector to obtain the results in this section. This dataset is significantly larger than the previous, containing approximately 300,000 time steps (~83 hour of signal data). This dataset outlines the scenarios at which this detector excels and its performance for medium window sizes. The standard deviation multiplier is significant. If the data follows a standard Gaussian distribution, the detected points would fall outside 99.999\% of the data present in the window, which would represent a significant outlier comparative to the rest of the data. The rolling range multiplier is disabled for this experiment since the outliers are not relational to each other. There are 4 different types of outliers which all have radically different behaviors and signal shapes, so it is not desired to compare or remember them in the context of the next outlier. The recent range detection debounce multiplier is only one due to the larger size of the time series window and overall window size.

\begin{table}[H]
%%\centering
\begin{tabular}{|l|c|l|}
    \hline
	\textbf{Parameter} & \textbf{Value} & \textbf{Description} \\ \hline
	m & 250 & Window Size \\ \hline
	ts$\_$size & 5000 & Time Series Size \\ \hline
	std$\_$dev & 4 & Standard Deviation Multiplier \\ \hline
	range & 0 & Rolling Range Multiplier\\ \hline
	recent & 1 & Recent Detection Debounce\\ \hline
\end{tabular}
\caption{PEC Data Set Detector Parameters}
\label{tab:pec_sim_params}
\end{table}

Figure \ref{fig:pec_mp_hist} shows the computed matrix profile values during the experiment. Because of the scale variance of the anomalies, only 2 of the 4 detected anomalies are visually represented in the figure. The 2 anomalies that are not depicted show similar patterns, but at much smaller scale. This shows the detector is able to perform on signals with widely differing anomaly characteristics and patterns.

\begin{figure}[H]
    %%\centering
    \input{2_pec_sim/mp_hist_f_c.pgf}
    \caption{PEC Data Set Matrix Profile Values}
    \label{fig:pec_mp_hist}
\end{figure}

Figure \ref{fig:pec_outliers} shows the anomalies detected by the algorithm in red, over the manually labeled anomaly (true/false values) start and end periods. The detector accurately determined the start and end of each anomaly (100\% detection rate) with no false positives (0\% error rate). It detected the start of each anomaly almost immediately quickly detected the end of the corresponding anomaly once it was over, although this takes more time in certain cases. By nature, anomalies are rare so interpreting the detection and false positive rates in a traditional way is not possible. The interpretation of the results and significance will be provided in section \ref{sec:discussion}.
 
\begin{figure}[H]
    %%\centering
    \input{2_pec_sim/outlier_result_f_c.pgf}
    \caption{PEC Data Set Anomalies}
    \label{fig:pec_outliers}
\end{figure}

\subsubsection{Cyber Security BETH Data Set}
\label{ref_results_beth_sim}
The Cyber Security BETH data set presented in section \ref{ref_beth_dataset} is used to perform this simulation. Table \ref{tab:beth_sim_params} specifies the parameters used with the anomaly detector to obtain the results in this section. This dataset is the largest of all in this study, containing approximately 800,000 time steps (~9 days of signal data). This dataset outlines the most challenging of the test scenarios for the detector and its performance for large window sizes. The standard deviation multiplier is the default. If the data follows a standard Gaussian distribution, the detected points would fall outside 99.7\% of the data present in the window, which would represent a significant outlier comparative to the rest of the data. The rolling range multiplier is set to one below the standard deviation multiplier for this experiment which provides some recall of previous outliers, but provides more weight to the present outlier detection score. The attacks have been manually labelled and although there are different kinds of attacks, the baseline signal (userId) remains the same. The recent range detection debounce multiplier is two due to the nature and volatility of the data.

\begin{table}[H]
%%\centering
\begin{tabular}{|l|c|l|}
    \hline
	\textbf{Parameter} & \textbf{Value} & \textbf{Description} \\ \hline
	m & 1000 & Window Size \\ \hline
	ts$\_$size & 10,000 & Time Series Size \\ \hline
	std$\_$dev & 3 & Standard Deviation Multiplier \\ \hline
	range & 2 & Rolling Range Multiplier\\ \hline
	recent & 2 & Recent Detection Debounce\\ \hline
\end{tabular}
\caption{BETH Data Set Model Parameters}
\label{tab:beth_sim_params}
\end{table}

Figure \ref{fig:beth_mp_hist} shows the computed matrix profile values for this experiment. In this study, the outliers are only present when there is a significantly large range spike as shown near time step 200,000. The regular and periodic small peaks prior are not outliers and the rolling range technique ensures they do not trigger the detector. This provides an example of how the rolling range parameter can be used to tune the memory and ability of the detector. 

\begin{figure}[H]
    %%\centering
    \input{3_beth_sim/mp_hist_userId.pgf}
    \caption{BETH Matrix Profile}
    \label{fig:beth_mp_hist}
\end{figure}

Figure \ref{fig:beth_sus_outliers} shows the algorithms detection results compared to the values considered suspicious by the creators of the BETH dataset. The BETH dataset researchers determined that many of the data points that are considered suspicious are not actually dangerous or evil as shown in figure \ref{fig:beth_evil_outliers}. In this case, the detector is able to discern fairly well where the evil outlier lie among the very noisy suspicious data points. This is the most challenging data set analyzed thus far and as such the results do not provide 100\% accuracy with no false positives.

 \begin{figure}[H]
    %%\centering
    \input{3_beth_sim/outlier_result_sus_userId.pgf}
    \caption{BETH Suspicious Outliers}
    \label{fig:beth_sus_outliers}
\end{figure}

Figure \ref{fig:beth_evil_outliers} shows the algorithms detection results compared to the values considered evil by the creators of the BETH dataset. The algorithm was able to detect the starts of the outliers within the debounce threshold and was able to detect the end of the faults with some delay. There are 2 false positives from the detector, which correspond to high UserID values in the dataset. These two locations are marked as suspicious so in this case the false positive would still be worth investigating even if it is deemed not evil.
 
\begin{figure}[H]
    %%\centering
    \input{3_beth_sim/outlier_result_evil_userId.pgf}
    \caption{BETH Evil Outliers}
    \label{fig:beth_evil_outliers}
\end{figure}

